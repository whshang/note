# 数据中台(数据集成篇) - 一寸HUI - 博客园

---

* [https://www.cnblogs.com/zsql/p/15798421.html](https://www.cnblogs.com/zsql/p/15798421.html)
* 声明：本文归属一寸HUI所有。@一寸HUI 在上一篇文章数据中台(架构篇)中了解到了数据中台的架构，其中，数据集成开发平台：数据集成开发平台能最高效地使用底层的组件和数据，提供从源数据到数据能力的转换
* 2022-08-01 20:46:23

---

**目录**

* [数据采集方法和工具](#_label0)

  * [1.线上行为采集](#_label0_0)
  * [2.线下行为采集](#_label0_1)
  * [3.互联网数据采集](#_label0_2)
* [数据分类](#_label1)
* [数据交换平台](#_label2)

  * [1.数据源管理](#_label2_0)
  * [2.离线数据交换](#_label2_1)
  * [3.实时数据交换](#_label2_2)
* [数据存储](#_label3)

---

声明：本文归属[https://home.cnblogs.com/u/zsql/](https://home.cnblogs.com/u/zsql/)​**[一寸HUI]()**所有。@一寸HUI

在上一篇文章[https://www.cnblogs.com/zsql/p/15771883.html](https://www.cnblogs.com/zsql/p/15771883.html)​**[数据中台(架构篇)]()** 中了解到了数据中台的架构，其中， **数据集成开发平台** ：数据集成开发平台能最高效地使用底层的组件和数据，提供从源数据到数据能力的转换。数据集成平台是数据中台数据接入的入口。数据中台本身几乎不产生数据，所有数据来自于业务系统、日志、文件、网络等，这些数据分散在不同的网络环境和存储平台中，难以利用，很难产生业务价值。数据集成是数据中台必须提供的核心工具，把各种异构网络、异构数据源的数据方便地采集到数据中台中进行集中存储，为后续的加工建模做准备。数据集成方式一般有数据库同步、埋点、网络爬虫、消息队列等；从汇聚的时效性来分，有离线批量汇聚和实时采集，也有增量同步和全量同步。在数据集成的过程中一般会用到datax，flume，sqoop，canal等工具。

要构建企业级的数据中台，第一步就是要让企业内部各个业务系统的数据实现互联互通，从物理上打破数据孤岛，这主要通过数据汇聚和交换的能力来实现。在面向具体场景时，可以根据数据类型将汇聚对象分为结构化和非结构化、大文件和小文件、离线与在线等几种，不同类型的数据对存储的要求不同。

在数据采集和汇聚过程中，需要特别注意的一点是数据的隐私和安全，数据采集和汇聚是最容易触碰法律红线的环节， 因此在制订相应的方案时，一定要考虑当地安全法规的要求，避免侵犯用户的个人隐私，导致用户信息安全受损。

## 数据采集方法和工具

### 1.线上行为采集

线上行为的主要载体可以分为传统互联网和移动互联网两种，对应的形态有PC系统、PC网页、H5、小程序、App、智能可穿戴设备等。在技术上，数据采集主要有客户端SDK埋点和服务端SDK埋点等方式。其中客户端SDK埋点主要是通过在终端设备内嵌入埋点功能模块，通过模块提供的能力采集客户端的用户行为，并上传回行为采集服务端。

**客户端埋点：**

* 全埋点：将终端设备上用户的所有操作和内容都记录并保存下来，只需要对内嵌SDK做一些初始配置就可以实现收集全部行为的目的。这也经常被称为无痕埋点、无埋点等。
* 可视化埋点：将终端设备上用户的一部分操作，通过服务端配置的方式有选择性地记录并保存。
* 代码埋点：根据需求来定制每次的收集内容，需要对相应的终端模块进行升级。

服务端埋点：

* 服务端埋点，通过在系统服务器端部署相应的数据采集模块，将这部分数据作为行为数据进行处理和分析。服务端埋点常见的形态有HTTP服务器中的access_log，即所有的Web服务的日志数据。

### 2.线下行为采集

* 线下行为数据主要通过一些硬件来采集，如常见的Wi-Fi探针、摄像头、传感器等。随着设备的升级，各种场景中对智能设备的应用也越来越多，安防、客户监测、考勤等都开始深入到生活中。常见的主要有Wi-Fi信号采集、信令数据采集、图像视频采集以及传感器探测等。

### 3.互联网数据采集

* 网络爬虫又称为网页蜘蛛，是一种按照既定规则自动抓取互联网信息的程序或者脚本，常用来做网站的自动化测试和行为模拟。

在数据能力建设过程中，很多企业结合自身的场景和最佳实践也开源了一些优秀的汇聚工具，如Flume、Flinkx，Sqoop、DataX、Canal等，适用场景不同，也各有优缺点。

## 数据分类

从**数据组织**形式来分，数据主要分成三类：

* 结构化数据：规则、完整，能够通过二维逻辑来表现的数据，严格遵循数据格式与长度规范，常见的有数据库表、Excel等二维表。
* 半结构化数据：数据规则、完整，同样严格遵循数据格式与长度规范，但无法通过二维关系来表现，常见如JSON、XML等形式表达的复杂结构。
* 非结构化数据：数据结构不规则或不完整，不方便用二维逻辑表来表现，需要经过复杂的逻辑处理才能提取其中的信息内容，如办公文档、图片、图像和音视频等。

从**时效性和应用场景**来分，数据汇聚可以分成离线和实时两类：

* 离线：主要用于大批量数据的周期性迁移，对时效性要求不高，一般采用分布式批量数据同步的方式，通过连接读取数据，读取数据过程中可以有全量、增量的方式，经过统一处理后写入到目标存储。
* 实时：主要面向低时延的数据应用场景，一般通过增量日志或通知消息的方式实现，如通过读取数据库的操作日志（RedoLog、BinLog）来实现相应的实时处理，业界常见的Canal、MaxWell、StreamSets、NiFi等框架和组件都有较多的实际应用。

## 数据交换平台

从数据类型来看，有结构化数据和非结构化数据；从实效性来看，有实时数据交换和离线数据交换。另外，数据交换应该是后续数据作业的起点，因此，相应的交换任务调度及状态要能够有效地与上下游形成依赖，借助统一调度的能力构建数据作业流。

数据交换中心的首要目的是屏蔽底层工具的复杂性，以可视化配置的方式提供给企业用户；其次需要考虑，为了解决数据孤岛，需要满足异构存储、异构数据类型的交换需求；同时，还要考虑不同时效要求下的数据互通。因此，数据交换平台需要屏蔽系统底层协议、传输安全、特性组件等信息，让开发人员在数据接入过程中无须关注数据格式转换、数据路由、数据丢失等，只需要关注与业务本身的数据交换部分。企业信息化建设的多种数据源类型，可以通过同步模块的数据源进行统一管理，方便用户快速通过可视化页面执行数据汇聚工作。

基于异构数据源、异构厂商集群、数据应用时效性和相关技术栈等因素考虑，采取了不同的同步策略：离线数据同步和实时数据同步。同时，在两种同步服务的产品形态上，可以采用相同的可视化同步配置策略，以降低用户操作成本。

### 1.数据源管理

数据源管理主要是管理数据所用的存储，用于平台在做数据交换时，可以方便地对外部存储进行相应的管理。数据源可以是已有系统存储业务数据的地方，作为数据中台的数据来源，也可以是数据应用场景，为应用场景提供结果数据存储的地方。根据业务系统以及数据应用场景的不同，数据源也有不同的选择。

数据源会有很多种，大致可以分成：

* 关系型数据库：如Oracle、MySQL、SQL Server、Greenplum等。
* NoSQL存储：如HBase、Redis、Elasticsearch、Cassandra、MongoDB、Neo4J等。
* 网络及MQ：如Kafka、HTTP等。
* 文件系统：如HDFS、FTP、OSS、CSV、TXT、Excel等。
* 大数据相关：如Hive、Impala、Kudu、MaxCompute、ADB、LibrA、

  ELK等

### 2.离线数据交换

离线数据交换是针对数据时效要求低、吞吐量大的场景，解决大规模数据的批量迁移问题，其实现原理是将不同数据源的交换抽象为从源头数据源读取数据的读取插件，以及向目标端写入数据的写入插件，理论上可以支持任意类型数据源的数据交换工作。采用插件化方式构建，将数据源读取和写入抽象成读取插件、写入插件。

* 读取插件：数据采集模块，负责采集数据源的数据，将数据发送给数据交换核心模块。
* 写入插件：数据写入模块，不断从数据交换核心模块取数据，并将数据写入到目的端。
* 数据交换核心模块：用于连接读取插件和写入插件，作为两者的数据传输通道，并处理缓冲、流控、并发、数据转换等核心技术问题。

离线数据同步：

* 前置稽核：在源端数据同步开始前，可以进行数据质量规则校验，根据配置规则的阻塞、告警等策略控制数据同步是否运行。
* 数据转换：数据转换是指将各类非标准数据转换成标准数据格式，并且将转换后的数据推送到大数据平台指定的位置或库表。在数据同步、传输过程中，存在用户对于数据传输进行定制化的场景，包括字段截取、替换、编码转换等操作，可以借助ETL的T过程（Transform）实现。
* 跨集群数据同步：数据同步模块可支持不同集群间的数据同步。
* 全量同步：全量数据同步分为表全量同步和库全量同步（整库同步）两种方式。表全量同步每次读取表中全量数据并写入；库全量同步策略是把库中所有表进行数据同步，要求源端和目的端的表名称、结构相同，允许目标表不存在，不存在时自动创建目标表。
* 增量同步：增量同步分为新增、覆盖和更新三种策略。新增策略主要通过在目的端创建新分区或者直接追加写数据实现。覆盖和更新策略在同步配置时选择唯一键，根据唯一键对比同步中的数据和目的端数据，结合增量策略来判断数据是覆盖还是更新。

### 3.实时数据交换

实时数据交换主要负责把数据库、日志、爬虫等数据实时接入Kafka、Hive、Oracle等存储中，便于后续进行实时计算或供业务查询分析使用。

实时同步有两个核心服务：数据订阅服务（Client Server）、数据消费服务（Consumer Server）。

数据订阅服务主要包含数据的订阅和读取、任务实例的启停控制等功能，Client Server采用插件式设计思路，可以支持扩展不同类型的数据订阅读取。

## 数据存储

类数据汇聚后，首先面临的是存储压力，不同类型的数据内容、不同的数据汇聚方式及未来可能的使用场景，对存储的选择也会有较多的考虑。常见的问题有：

* 存储是选择关系型数据库还是大数据相关的技术（Hadoop等）？
* 现有的存储与新存储之间的关系是什么？

除了上面要考的内容，还要考虑如下内容：

* 数据规模：当前的数据规模以及未来的数据规模，这取决于对中台的定位及未来的发展预期，DT时代企业的数据生产方式越来越丰富，数据量越来越大，选择成本可控且容易扩展的存储是当前比较常见的选择。
* 数据生产方式：有些数据生产端没有存储，因此会通过实时推送的方式将生产数据按特定协议和方式进行推送，这类场景要求数据采集时的存储能够满足数据实时落地的需求。有些目标存储不具备这种高性能落地的能力，因此需要考虑在数据生产端和目标存储端中间加一个写性能较好的存储。
* 数据应用方式：数据使用场景决定了数据存储的选型，如离线的数据分析适合非人机交互的场景，搜索则需要能够快速检查并支持一些关键字和权重处理。这些能力也需要有特定的存储来支撑。
* 在线存储or离线存储：在线存储是指存储设备和所存储的数据时刻保持“在线”状态，可供用户随意读取，满足计算平台对数据访问的速度要求，就像PC机中常用的磁盘存储模式一样。在线存储设备一般为磁盘、磁盘阵列、云存储等。离线存储是为了对在线存储的数据进行备份，以防范可能发生的数据灾难。离线存储的访问速度慢、效率低。离线存储的典型产品是硬盘、磁带和光盘等。

当然数据集成平台在建设的过程中要考虑到用户的体验，在管理好数据源的基础上，里面的表字段做到可视化，源表和目标表的字段自动对其，方便查看和排查问题，还有就是要考虑数据质量，避免重复接入，或者接入脏数据，脏数据可以在源端控制好，或者直接丢弃，既然是集成，当然是之多各种各样的数据源，同步方式也要支持多种，做到可视化，做好数据集成监控，还有就是接入的数据存放在哪里，所以在接入的存放点我们要设置好规范，不能乱接入，命名规范（可以看下[https://blog.csdn.net/gjggw123/article/details/107865285](https://blog.csdn.net/gjggw123/article/details/107865285)​**[数据中台-实施篇：数据接入相关规范]()**）。还有就是各种作业的命名规范，最好一眼就能看出来这个作业名是从哪里到哪里，是什么业务的什么表等。数据集成平台最好做到零代码开发接入，通过配置等就可以实现各个数据存储系统之间的相互接入。

**参考：**

《数据中台：让数据用起来》

[数据采集与埋点](https://blog.csdn.net/yue_2018/article/details/89243715)

[数据埋点怎么做](https://www.zhihu.com/question/319699149/answer/1229854658)

[基于Apache doris怎么构建数据中台(四)-数据接入系统](https://hf200012.github.io/2021/08/%E5%9F%BA%E4%BA%8EApache-doris%E6%80%8E%E4%B9%88%E6%9E%84%E5%BB%BA%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0(%E5%9B%9B)-%E6%95%B0%E6%8D%AE%E6%8E%A5%E5%85%A5%E7%B3%BB%E7%BB%9F/)
