# AI Agent 提示设计：如何让 Agent 听懂你的需求

刚开始使用 AI Agent 时，总是遇到一个问题，明明说得很清楚了，为什么 Agent 还是做错了。后来发现问题不在 Agent 而在我。让 Agent 听懂和让人听懂完全是两回事。

想让 Agent 帮分析一份代码，写了这样的提示，请帮我看看这份代码，看看有没有问题，如果有问题请告诉我怎么改，谢谢。Agent 回答代码看起来没问题，建议保持现有结构，没有发现明显错误。但实际上这份代码有严重的性能问题。问题在于指令不够具体，看看有没有问题什么类型的问题，怎么改改进的方向是什么。缺少评判标准，什么样的代码算有问题，什么样的修改算好。期望不明确，想要详细的分析，Agent 只给了模糊的判断。

吸取教训后开始写技术的提示，请执行静态代码分析，检查以下指标，时间复杂度、空间复杂度、内存泄漏风险、并发安全问题、代码规范符合度。Agent 严格按照指标分析，但忽略了业务逻辑问题，给出的建议过于理论化，没有考虑实际运行环境。过度技术化让 Agent 变成了检查工具而不是分析助手。

经过多次试错，总结了一个 Agent 提示设计框架。结构包括角色、Agent 的身份和职责、任务、具体要完成什么、上下文、关键背景信息、约束、必须遵守的规则、评判标准、如何判断好坏、输出格式、期望的输出结构。

用上面的代码分析例子，现在的提示是角色为资深后端开发工程师专注性能优化，任务是分析这份代码的性能和可维护性问题，上下文是这是一个高频调用的服务接口每秒处理一千加请求。约束包括重点关注数据库查询和循环嵌套，考虑内存使用和响应时间，提供具体的优化建议。评判标准包括性能响应时间小于一百毫秒，可维护性代码复杂度小于十圈复杂度。输出格式包括问题列表按严重程度排序，每个问题的优化建议，预期改进效果。Agent 现在能准确识别性能瓶颈，提供具体的优化建议，评估改进后的效果，优先处理严重问题。

角色定义要具体。模糊角色是代码分析师，具体角色是资深后端开发工程师有十年 Java 开发经验专注高并发系统优化。具体的角色定义能帮助 Agent 更好地理解任务。

复杂任务要分解成子任务。分析整个系统可以分解成分析数据库性能、分析缓存策略、分析接口响应、分析错误处理。

告诉 Agent 什么是好什么是坏。性能标准，响应时间小于一百毫秒优秀，响应时间一百到三百毫秒良好，响应时间大于三百毫秒需要优化。代码标准，圈复杂度小于五优秀，圈复杂度五到十良好，圈复杂度大于十需要重构。

明确告诉 Agent 想要什么格式。执行摘要一到两句话，详细分析问题加建议，优先级排序紧急重要一般，预期收益量化改进。

让 Agent 写测试用例之前模糊提示是请为这个函数写一些测试用例谢谢。现在结构化提示，角色为测试工程师专注单元测试，任务是为这个函数写单元测试用例，上下文是这是一个用户验证函数用于生产环境。约束包括覆盖所有分支逻辑，包含边界条件测试，使用 Jest 框架。评判标准包括测试覆盖率大于百分之九十，包含正常流程和异常流程。输出格式包括测试用例列表描述加输入加期望输出，完整的测试代码，预期覆盖率。结果测试用例更全面，代码质量更高。

每次设计 Agent 提示时会检查，角色是否具体不是助手而是工程师，任务是否明确具体要完成什么，上下文是否充分关键背景信息，约束是否清晰必须遵守的规则，评判标准是否明确如何判断好坏，输出格式是否具体期望的具体结构。

AI Agent 不是人类它不会猜测意图。必须明确告诉它你是谁角色、要做什么任务、为什么要做上下文、有什么限制约束、什么样算好评判标准、要做成什么样输出格式。好的 Agent 提示设计关键在结构化、具体化、标准化、量化。这套方法让和 Agent 的协作效率提升了三倍。
